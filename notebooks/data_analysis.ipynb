{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = (20,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/avatar.csv', encoding = 'unicode_escape').drop(columns=['Unnamed: 0', 'id'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "speakers = df.groupby(['character']).size().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.bar(x=speakers.index[:20], height=speakers.values[:20] / speakers.values.sum() * 100)\n",
    "plt.xticks(rotation=-45)\n",
    "plt.title('20 most common speakers')\n",
    "plt.ylabel('Number of quotes (%)')\n",
    "plt.xlabel('Speaker name')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Preprocessing\n",
    "The plot above shows that there is character named \"Scene Description\". Scene descriptions are useless for the sake of text (speach) generation. We verify its participation in the whole dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "total = df.shape[0]\n",
    "characters = df[df['character'] != 'Scene Description'].shape[0]\n",
    "descriptions = df[df['character'] == 'Scene Description'].shape[0]\n",
    "print(f\"{'Total number of expressions:':<30}{total:<10}\")\n",
    "print(f\"{'Characters statements:':<30}{characters:<6}( {characters/total * 100:.2f}% )\")\n",
    "print(f\"{'Scene descriptions:':<30}{descriptions:<6}( {descriptions/total * 100:.2f}% )\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "There are also some troublesome characters in the file:\n",
    "\n",
    "| occurences    | character         |\n",
    "|---------------|-------------------|\n",
    "| 1766          | Aang              |\n",
    "| 2             | Aang and Sokka    |\n",
    "| 1             | Aang and Zuko     |\n",
    "| 1             | Aang:             |\n",
    "| 1             | Actor Bumi        |\n",
    "| 5             | Actor Iroh        |\n",
    "| 2             | Actor Jet         |\n",
    "| 5             | Actor Ozai        |\n",
    "| 16            | Actor Sokka       |\n",
    "| 3             | Actor Toph        |\n",
    "| 14            | Actor Zuko        |\n",
    "| 19            | Actress Aang      |\n",
    "| 10            | Actress Azula     |\n",
    "| 16            | Actress Katara    |\n",
    "\n",
    "Hence, we perform some preprocessing, consecutively executing the following steps:\n",
    "1. Drop scene descriptions.\n",
    "2. Drop statements spoken by more than 1 character - there is no simple way to assign them to the proper character. Thus, to avoid manual labeling we drop them, because there are only few of thems.\n",
    "3. Lower all character names.\n",
    "4. Remove tokens like \":\", \"actor\", \"actress\" from character names.\n",
    "5. Transform name to upper case.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/avatar.csv', encoding = 'unicode_escape').drop(columns=['Unnamed: 0', 'id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = df[df['character'] != 'Scene Description']\n",
    "df = df[~df['character'].str.contains('and')]\n",
    "df['character'] = df['character'].str.lower()\n",
    "df['character'] = df['character'].str.replace(':|actor|actress', '', regex=True)\n",
    "df['character'] = df['character'].str.strip().str.title()\n",
    "df = df.reset_index()\n",
    "df = df.drop(columns=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "speakers = df.groupby(['character']).size().sort_values(ascending=False)\n",
    "\n",
    "plt.bar(x=speakers.index[:20], height=speakers.values[:20] / speakers.values.sum() * 100)\n",
    "plt.xticks(rotation=-45)\n",
    "plt.title('20 most common speakers')\n",
    "plt.ylabel('Number of quotes (%)')\n",
    "plt.xlabel('Speaker name')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Exploratory Data Analysis\n",
    "## English in atla and ordinary world\n",
    "We want to verify whether general english and atla english are similar. To determine this we compare most frequent words in both english types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import nltk\n",
    "\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "def get_wordnet_pos(treebank_tag):\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return nltk.corpus.wordnet.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return nltk.corpus.wordnet.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return nltk.corpus.wordnet.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return nltk.corpus.wordnet.ADV\n",
    "    else:\n",
    "        return nltk.corpus.wordnet.NOUN\n",
    "\n",
    "lemmatize = lambda x: lemmatizer.lemmatize(x, get_wordnet_pos(nltk.pos_tag([x])[0][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "freq_atla = df['character_words'].str.lower().str.replace('[^\\w\\s]', '', regex=True).str.split(expand=True).stack().apply(lemmatize).value_counts().reset_index()\n",
    "freq_atla[0] = (freq_atla[0] / sum(freq_atla[0]))\n",
    "freq_atla = freq_atla.values[:20, 0].tolist()\n",
    "freq_eng = requests.get('https://raw.githubusercontent.com/pkLazer/password_rank/master/4000-most-common-english-words-csv.csv').text.splitlines()[1:101]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(f'Differences: {len(set(freq_atla).difference(freq_eng[:20]))}')\n",
    "print('Popular in atla but not in common english')\n",
    "print(set(freq_atla).difference(freq_eng[:20]))\n",
    "print('Popular in common english but not in atla')\n",
    "print(set(freq_eng[:20]).difference(freq_atla))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We can observe that differences are minor. Mismatched tokens are similar parts of speach. The only difference seems to be that in atla more often singular forms of persons are used than in ordinary english (in which more plural forms are used). But proposed comparison is pretty imperfect. Some minor differences, like word from the atla subset being 21st most popular in ordinary language is counted as an error. Thus, we look for words that are in 20 most popular in atla, but don't occur in first 100 tokens of common english."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(len(set(freq_atla).difference(freq_eng[:100])))\n",
    "print(set(freq_atla).difference(freq_eng[:100]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "It's very surprising that so many tokens are not included in first 100 tokens. This confirms hypothesis that in atla many sentences are spoken using \"I\", \"me\" or \"my\".\n",
    "\n",
    "## Characters similarities\n",
    "In this step we want to find most similar characters. The similarity will be determined using pairwise cosine similarity between tf-idf representation of all statements spoken by a character merged to one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "join = lambda x: ' '.join(sum([val for val in x.values], []))\n",
    "\n",
    "df_temp = pd.DataFrame(df['character_words'].str.lower().str.replace('[^\\w\\s]', '', regex=True).str.split(expand=False))\n",
    "df_temp.insert(0, 'character', df['character'])\n",
    "df_temp = df_temp.groupby('character').agg({'character_words': join})\n",
    "\n",
    "cos_sim = cosine_similarity(TfidfVectorizer().fit_transform(df_temp['character_words'].tolist()))\n",
    "np.fill_diagonal(cos_sim, 0)\n",
    "\n",
    "idxs = np.unravel_index(np.argsort(cos_sim.ravel())[-10:], cos_sim.shape)\n",
    "idxs = np.array(idxs).T\n",
    "idxs.sort(axis=1)\n",
    "idxs = np.unique(idxs, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for i, (x, y) in enumerate(idxs):\n",
    "    print(f'{df_temp.index[x]} and {df_temp.index[y]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Similarities between Aand, Katara and Sokka may be explained quite easy as they are main characters who spent most of the time together. Thus they language is similar (here we can recall polish sentence about talking in companion of crows). The second very interesting thing is similarity between Brainwasher and Joo Does - there is a sceen when Joo Dees repeets Brainwasher's words."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}