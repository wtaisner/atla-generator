{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "NAME = \"Iroh\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Markov chains"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import src.markovChatbot as mc\n",
    "from src.markovChatbot import MarkovChatbot, transform_dialogues\n",
    "from src.data import read_dataframe"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "NGRAM_SIZE = 5\n",
    "CORPUS_SIZE = 1000\n",
    "LEN_MSG = 100\n",
    "\n",
    "text = transform_dialogues(size=CORPUS_SIZE)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def markov_for_character(name: str) -> MarkovChatbot:\n",
    "    \"\"\"\n",
    "    generates Markov chatbot for given character name\n",
    "    :param name: name of the character, e.g., Iroh\n",
    "    :return: MarkovChatbot\n",
    "    \"\"\"\n",
    "    df = read_dataframe()\n",
    "    df = df[df.character == name]\n",
    "    df = list(df.character_words)\n",
    "    df = \" \".join(df)\n",
    "    m = MarkovChatbot(text, n=NGRAM_SIZE)\n",
    "    m.fine_tune(df)\n",
    "\n",
    "    return m"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "to quit write \"quit\"\n",
      "Bot: you i you dining kidding i think bought it use a have on lost afraid don dog wrong idea of lost like shirt it at to are on health 35 no i oh cant you dont feel on was give dont that about a five look like the is your the me should me crew sure the rocks dont wrong can bus save know youre know hamburgers best rocks can know name couldnt save can hamburgers believe lend lend can believe your window take some come anything question some some know how save know check believe all know back i\n"
     ]
    }
   ],
   "source": [
    "markov_model = markov_for_character(NAME)\n",
    "mc.chat_with_me(markov_model, len_message=LEN_MSG)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# DialoGPT"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import src.DialoGPT as dialo"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "DIALO_MODEL = \"microsoft/DialoGPT-small\"\n",
    "DIALO_DIR = f\"../outputs/DialoGPT/{NAME}\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "dialo_model = AutoModelForCausalLM.from_pretrained(DIALO_DIR)\n",
    "dialo_tokenizer = AutoTokenizer.from_pretrained(DIALO_MODEL)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "to quit write \"quit\"\n",
      "Bot: I am...\n",
      "Bot: It's a dream come true.  I met Jasmine and she was very sweet.  And then I had to leave because I couldn't bear the heat of the Fire Nation.  But it was so worth it.\n",
      "Bot: You should have chosen a better teacher.\n",
      "Bot: No, Prince Zuko, it's time to leave.\n",
      "Bot: You must be proud.\n",
      "Bot: No. Uncle Iroh is my father.\n",
      "Bot: I don't want to see Uncle Irohs face the Fire Lord.\n",
      "Bot: Uncle?\n",
      "Bot: Uncles are here.\n"
     ]
    }
   ],
   "source": [
    "dialo.chat_with_me(dialo_model, dialo_tokenizer)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# BlenderBot"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "from transformers import BlenderbotSmallTokenizer, BlenderbotSmallForConditionalGeneration\n",
    "\n",
    "import src.blenderbot as bb"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "BLENDER_MODEL = \"facebook/blenderbot_small-90M\"\n",
    "\n",
    "BLENDER_DIR = f\"../outputs/blenderbot/{NAME}\"\n",
    "\n",
    "SRC_LEN = 512"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "blender_model = BlenderbotSmallForConditionalGeneration.from_pretrained(BLENDER_DIR)\n",
    "blender_tokenizer = BlenderbotSmallTokenizer.from_pretrained(BLENDER_MODEL)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "to quit write \"quit\"\n",
      "Bot: i'm doing well. it's been a long time since i've had to work, but i'll be sure to take my time to rest. you?\n"
     ]
    }
   ],
   "source": [
    "bb.chat_with_me(blender_model, blender_tokenizer, src_len=SRC_LEN)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# T5"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "\n",
    "import src.GoogleT5 as t5"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "T5_MODEL = 't5-base'\n",
    "\n",
    "T5_DIR = f\"../outputs/T5/T5_{NAME}\"\n",
    "\n",
    "MAX_SOURCE_TEXT_LENGTH = 256\n",
    "MAX_TARGET_TEXT_LENGTH = 128"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "t5_model = T5ForConditionalGeneration.from_pretrained(T5_DIR)\n",
    "t5_tokenizer = T5Tokenizer.from_pretrained(T5_MODEL, model_max_length=MAX_SOURCE_TEXT_LENGTH)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "t5.chat_with_me(t5_model, t5_tokenizer)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}