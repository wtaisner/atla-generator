{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 164,
   "outputs": [],
   "source": [
    "STEPS = 3\n",
    "NAME = \"Iroh\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Markov chains"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "outputs": [],
   "source": [
    "from src.markovChatbot import chat_with_me, MarkovChatbot, transform_dialogues\n",
    "from src.data import read_dataframe"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "outputs": [],
   "source": [
    "NGRAM_SIZE = 5\n",
    "CORPUS_SIZE = 1000\n",
    "LEN_MSG = 100\n",
    "\n",
    "text = transform_dialogues(size=CORPUS_SIZE)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "outputs": [],
   "source": [
    "def markov_for_character(name: str) -> MarkovChatbot:\n",
    "    \"\"\"\n",
    "    generates Markov chatbot for given character name\n",
    "    :param name: name of the character, e.g., Iroh\n",
    "    :return: MarkovChatbot\n",
    "    \"\"\"\n",
    "    df = read_dataframe()\n",
    "    df = df[df.character == name]\n",
    "    df = list(df.character_words)\n",
    "    df = \" \".join(df)\n",
    "    m = MarkovChatbot(text, n=NGRAM_SIZE)\n",
    "    m.fine_tune(df)\n",
    "\n",
    "    return m"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = markov_for_character(NAME)\n",
    "chat_with_me(model, len_message=LEN_MSG, steps=STEPS)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# DialoGPT"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from src.DialoGPT import chat_with_me"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "outputs": [],
   "source": [
    "MODEL = \"microsoft/DialoGPT-small\"\n",
    "DIALO_DIR = f\"../outputs/DialoGPT/{NAME}\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(DIALO_DIR)\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "chat_with_me(model, tokenizer, steps=STEPS)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# BlenderBot"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "outputs": [],
   "source": [
    "from transformers import BlenderbotSmallTokenizer, BlenderbotSmallForConditionalGeneration\n",
    "\n",
    "from src.blenderbot import chat_with_me"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "outputs": [],
   "source": [
    "MODEL = \"facebook/blenderbot_small-90M\"\n",
    "\n",
    "BLENDER_DIR = f\"../outputs/blenderbot/{NAME}\"\n",
    "\n",
    "SRC_LEN = 512"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "outputs": [],
   "source": [
    "model = BlenderbotSmallForConditionalGeneration.from_pretrained(BLENDER_DIR)\n",
    "tokenizer = BlenderbotSmallTokenizer.from_pretrained(MODEL)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "chat_with_me(model, tokenizer, steps=STEPS, src_len=SRC_LEN)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}